x = "colours",
y = "DQ_U_o_trans"
) +
theme_minimal()
# Simple linear regression (pooled across participants)
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans)) +
# Single global regression line in black
geom_smooth(
data = participant_data,
aes(x = colours, y = DQ_U_o_trans),
method = "lm",
inherit.aes = FALSE,
se = FALSE,
color = "black",
linewidth = 0.9
) +
# Points
geom_point(aes(x = colours, y = DQ_U_o_trans)) +
labs(
x = "colours",
y = "DQ_U_o_trans"
) +
theme_minimal()
# Simple linear regression (pooled across participants)
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans)) +
# Single global regression line in black
geom_smooth(
data = participant_data,
aes(x = colours, y = DQ_U_o_trans),
method = "lm",
inherit.aes = FALSE,
se = FALSE,
color = "black",
linewidth = 0.9
) +
# Points
geom_point(aes(x = colours, y = DQ_U_o_trans)) +
labs(
x = "colours",
y = "DQ_U_o_trans"
) +
theme_minimal()
# Multiple regressions by participant
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans, color = participantID)) +
# One regression line per participant (colored by participantID)
geom_smooth(
method = "lm",
se = FALSE,
size = 0.9
) +
# Points (also colored by participantID)
geom_point() +
labs(
x = "colours",
y = "DQ_U_o_trans"
) +
theme_minimal()
# Multiple regressions by participant
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans, color = participantID)) +
# One regression line per participant (colored by participantID)
geom_smooth(
method = "lm",
se = FALSE,
linewidth = 0.9
) +
# Points (also colored by participantID)
geom_point() +
labs(
x = "colours",
y = "DQ_U_o_trans"
) +
theme_minimal()
# Simple linear regression (pooled across participants)
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans)) +
# Single global regression line in black
geom_smooth(
data = participant_data,
aes(x = colours, y = DQ_U_o_trans),
method = "lm",
inherit.aes = FALSE,
se = FALSE,
color = "black",
linewidth = 0.9
) +
# Points
geom_point(aes(x = colours, y = DQ_U_o_trans)) +
labs(
x = "colours",
y = "DQ_U_o_trans"
) +
theme_minimal()
# Multiple regressions by participant
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans, color = participantID)) +
# One regression line per participant (colored by participantID)
geom_smooth(
method = "lm",
se = FALSE,
linewidth = 0.9
) +
# Points (also colored by participantID)
geom_point() +
labs(
x = "colours",
y = "DQ_U_o_trans"
) +
theme_minimal()
View(participant_data)
# Convert participantID to character in base R
participant_data$participantID <- as.character(participant_data$participantID)
# One regression line per participant (colored by participantID)
geom_smooth(
# Multiple regressions by participant
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans, color = participantID +
# Multiple regressions by participant
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans, color = participantID)) +
# One regression line per participant (colored by participantID)
geom_smooth(
method = "lm",
se = FALSE,
linewidth = 0.9
) +
# Points (also colored by participantID)
geom_point() +
labs(
x = "colours",
y = "DQ_U_o_trans"
) +
theme_minimal()
# Multiple regressions by participant
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans, color = participantID)) +
# Simple linear regression (pooled across participants)
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans)) +
# Single global regression line in black
geom_smooth(
data = participant_data,
aes(x = colours, y = DQ_U_o_trans),
method = "lm",
inherit.aes = FALSE,
se = FALSE,
color = "black",
linewidth = 0.9
) +
# Points
geom_point(aes(x = colours, y = DQ_U_o_trans)) +
labs(
x = "colours",
y = "DQ_U_o_trans"
) +
theme_minimal()
# Convert participantID to character in base R
participant_data$participantID <- as.character(participant_data$participantID)
# Multiple regressions by participant
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans, color = participantID)) +
# One regression line per participant (colored by participantID)
geom_smooth(
method = "lm",
se = FALSE,
linewidth = 0.9
) +
# Points (also colored by participantID)
geom_point() +
labs(
x = "colours",
y = "DQ_U_o_trans"
) +
theme_minimal()
# Display a summary of the fitted model
print(summary(model_1))
print(summary(model_2))
# Compute marginal likelihoods via bridgesampling for each model
bridge_1 <- bridge_sampler(model_1)
bridge_2 <- bridge_sampler(model_2)
# Calculate the Bayes factor (BF) comparing Model A to Model B.
# BF_21 > 3
bf_value_1 <- bridgesampling::bf(bridge_2, bridge_1)
print(bf_value_1)
#bf_value_2 <- bridgesampling::bf(bridge_1, bridge_2)
#print(bf_value_2)
print(summary(random_slope_model_1))
print(summary(random_slope_model_2))
# Compute marginal likelihoods via bridgesampling for each model
bridge_1_rs <- bridge_sampler(random_slope_model_1)
bridge_2_rs <- bridge_sampler(random_slope_model_2)
# Calculate the Bayes factor (BF) comparing Model A to Model B.
# BF_21 > 3
bf_value_rs_1 <- bridgesampling::bf(bridge_2_rs, bridge_1_rs)
print(bf_value_rs_1)
#bf_value_rs_2 <- bridgesampling::bf(bridge_1_rs, bridge_2_rs)
#print(bf_value_rs_2)
# Set seed and initialize df
seed_nums <- 1:10
sim_df <- tibble(
sim_no = integer(),
y_observed = numeric(),
y_sim = numeric()
)
for (i in seed_nums) {
set.seed(i)
# Variance / standard deviation priors for row-level noise
sigma0 <- rnorm(1, mean = 0, sd = 100)
sigma  <- abs(rnorm(nrow(participant_data), mean = 0, sd = sigma0))
epsilon <- rnorm(nrow(participant_data), mean = 0, sd = sigma)
# Fixed effects priors
b0 <- rnorm(1, mean = 0, sd = 100)       # Global intercept
FE <- rnorm(3, mean = -0.3, sd = 1)      # Slopes for 3 fixed effects
# Random intercept with a half-Cauchy(0,1) prior on its SD
# Step 1: Draw the SD from a half-Cauchy by taking abs(rcauchy(...))
b0_sd <- abs(rcauchy(1, location = 0, scale = 1))
# Step 2: Draw participant-specific intercepts from N(0, b0_sd)
participantIDs <- unique(participant_data$participantID)
b0_re <- rnorm(length(participantIDs), mean = 0, sd = b0_sd)
# Match each row in participant_data to the correct participant intercept
id_idx <- match(participant_data$participantID, participantIDs)
# Linear predictor (example):
# Global intercept + participant-specific intercept + slope for 'urns' + noise
yhat <- b0 + b0_re[id_idx] + FE[1] * participant_data$urns +
FE[2] * participant_data$colours + FE[3] * participant_data$seqBall + epsilon
# Store the results for this simulation
sims <- tibble(
sim_no = i,
y_observed = participant_data$DQ_U_o_trans,
y_sim = yhat
)
# Append to the main data frame
sim_df <- bind_rows(sim_df, sims)
}
print(FE[1])
print(FE[2])
print(FE[3])
print(FE[0])
print(FE[4])
head(sim_df)
# Set seed and initialize df
seed_nums <- 1:10
sim_df <- tibble(
sim_no = integer(),
y_observed = numeric(),
y_sim = numeric()
)
for (i in seed_nums) {
set.seed(i)
# Variance / standard deviation priors for row-level noise
sigma0 <- rnorm(1, mean = 0, sd = 100)
sigma  <- abs(rnorm(nrow(participant_data), mean = 0, sd = sigma0))
epsilon <- rnorm(nrow(participant_data), mean = 0, sd = sigma)
# Fixed effects priors
b0 <- rnorm(1, mean = 0, sd = 100)       # Global intercept
FE <- rnorm(3, mean = -0.3, sd = 1)      # Slopes for 3 fixed effects
# Random intercept with a half-Cauchy(0,1) prior on its SD
# Step 1: Draw the SD from a half-Cauchy by taking abs(rcauchy(...))
b0_sd <- abs(rcauchy(1, location = 0, scale = 1))
# Step 2: Draw participant-specific intercepts from N(0, b0_sd)
participantIDs <- unique(participant_data$participantID)
b0_re <- rnorm(length(participantIDs), mean = 0, sd = b0_sd)
# Match each row in participant_data to the correct participant intercept
id_idx <- match(participant_data$participantID, participantIDs)
# Linear predictor (example):
# Global intercept + participant-specific intercept + slope for 'urns' + noise
yhat <- b0 + b0_re[id_idx] + FE[1] * participant_data$urns +
FE[2] * participant_data$colours + FE[3] * participant_data$seqBall + epsilon
# Store the results for this simulation
sims <- tibble(
sim_no = i,
y_observed = participant_data$DQ_U_o_trans,
y_sim = yhat
)
# Append to the main data frame
sim_df <- bind_rows(sim_df, sims)
}
head(sim_df)
# Set seed and initialize df
seed_nums <- 1:10
sim_df <- tibble(
sim_no = integer(),
y_observed = numeric(),
y_sim = numeric()
)
for (i in seed_nums) {
set.seed(i)
# Variance / standard deviation priors for row-level noise
sigma0 <- abs(rnorm(1, mean = 0, sd = 100))  # ensure sigma0 is nonnegative
sigma  <- abs(rnorm(nrow(participant_data), mean = 0, sd = sigma0))
# Use participant_data (not bounce_data) for epsilon:
epsilon <- rnorm(nrow(participant_data), mean = 0, sd = sigma)
# Fixed effects priors
b0 <- rnorm(1, mean = 0, sd = 100)       # Global intercept
FE <- rnorm(3, mean = -0.3, sd = 1)        # Slopes for 3 fixed effects
# Random intercept with a half-Cauchy(0,1) prior on its SD
# Draw SD from a half-Cauchy by taking the absolute value of rcauchy
b0_sd <- abs(rcauchy(1, location = 0, scale = 1))
# Draw participant-specific intercepts from N(0, b0_sd)
participantIDs <- unique(participant_data$participantID)
b0_re <- rnorm(length(participantIDs), mean = 0, sd = b0_sd)
# Match each row in participant_data to the correct participant intercept
id_idx <- match(participant_data$participantID, participantIDs)
# Linear predictor (example):
# Global intercept + participant-specific intercept + slopes for predictors + noise
yhat <- b0 + b0_re[id_idx] +
FE[1] * participant_data$urns +
FE[2] * participant_data$colours +
FE[3] * participant_data$seqBall +
epsilon
# Store the results for this simulation
sims <- tibble(
sim_no = i,
y_observed = participant_data$DQ_U_o_trans,
y_sim = yhat
)
# Append to the main data frame
sim_df <- bind_rows(sim_df, sims)
}
head(sim_df)
# Set seed and initialize df
seed_nums <- 1:10
sim_df <- tibble(
sim_no = integer(),
y_observed = numeric(),
y_sim = numeric()
)
for (i in seed_nums) {
set.seed(i)
# Variance / standard deviation priors for row-level noise
sigma0 <- abs(rnorm(1, mean = 0, sd = 100))  # ensure sigma0 is nonnegative
sigma  <- abs(rnorm(nrow(participant_data), mean = 0, sd = sigma0))
# Use participant_data (not bounce_data) for epsilon:
epsilon <- rnorm(nrow(participant_data), mean = 0, sd = sigma)
# Fixed effects priors
b0 <- rnorm(1, mean = 0, sd = 100)       # Global intercept
FE <- rnorm(3, mean = -0.3, sd = 1)        # Slopes for 3 fixed effects
## Precision parameter phi from Gamma(2, 0.1)
phi <- rgamma(1, shape = 2, rate = 0.1)
# Random intercept with a half-Cauchy(0,1) prior on its SD
# Draw SD from a half-Cauchy by taking the absolute value of rcauchy(0,1)
b0_sd <- abs(rcauchy(1, location = 0, scale = 1))
# Draw participant-specific intercepts from N(0, b0_sd)
participantIDs <- unique(participant_data$participantID)
b0_re <- rnorm(length(participantIDs), mean = 0, sd = b0_sd)
# Match each row in participant_data to the correct participant intercept
id_idx <- match(participant_data$participantID, participantIDs)
# Linear predictor (example):
# Global intercept + participant-specific intercept + slopes for predictors + noise
## Linear predictor (eta)
# Note: no additive error term here; variability comes from the Beta distribution
eta <- b0 + b0_re[id_idx] +
FE[1] * participant_data$urns +
FE[2] * participant_data$colours +
FE[3] * participant_data$seqBall
# Transform linear predictor using logistic function to obtain mu in (0,1)
mu <- 1 / (1 + exp(-eta))
# Calculate Beta distribution parameters for each row
alpha_param <- mu * phi
beta_param <- (1 - mu) * phi
# Simulate yhat from the Beta distribution for each observation
yhat <- rbeta(nrow(participant_data), shape1 = alpha_param, shape2 = beta_param)
# Store the results for this simulation
sims <- tibble(
sim_no = i,
y_observed = participant_data$DQ_U_o_trans,
y_sim = yhat
)
# Append to the main data frame
sim_df <- bind_rows(sim_df, sims)
}
head(sim_df)
# Create an animated plot showing how observed vs. simulated data changes
# across different simulation runs.
ggplot(sim_df, aes(x = y_observed, y = y_sim)) +
geom_point() +
ggtitle("Simulation #: {closest_state}") +
labs(
x = "Observed (DQ_U_o_trans)",
y = "Simulated (Beta regression)"
) +
theme_minimal() +
theme(title = element_text(size = 7)) +
transition_states(
as.factor(sim_no),
transition_length = 1,
state_length = 10
) +
view_follow()
#install.packages("brms","dplyr")
#install.packages("devtools")
#devtools::install_github("tidyverse/tidyverse")
#devtools::install_github("thomasp85/gganimate")
knitr::opts_chunk$set(echo = TRUE)
library(brms)
library(dplyr)
library(tidyverse)
library(gganimate)
library(bayesplot)
setwd("~/OneDrive - The University of Melbourne/Bayesian Updating and Complexity/Code/Analysis")
participant_data <- read.csv("participant_data.csv")
# Set seed for reproducibility
set.seed(12)
# Function to add small random noise to selected columns in the dataset
add_noise <- function(data, noise_sd = 0) {
data %>%
mutate(
responseTimeUrn = responseTimeUrn + rnorm(n(), mean = 0, sd = noise_sd),
responseTimeColour = responseTimeColour + rnorm(n(), mean = 0, sd = noise_sd),
DQ_U_o = DQ_U_o + rnorm(n(), mean = 0, sd = noise_sd),
DQ_C_o = DQ_C_o + rnorm(n(), mean = 0, sd = noise_sd),
DQ_U_s = DQ_U_s + rnorm(n(), mean = 0, sd = noise_sd),
DQ_C_s = DQ_C_s + rnorm(n(), mean = 0, sd = noise_sd)
)
}
# Create three synthetic datasets by duplicating the original data and adding noise
synthetic_data_list <- lapply(1:3, function(i) {
synthetic <- add_noise(participant_data, noise_sd = 0)
# Optionally, modify the participantID to reflect the synthetic duplication.
synthetic <- synthetic %>%
mutate(participantID = paste0(participantID, "_synth", i))
return(synthetic)
})
# Combine the original dataset with the synthetic datasets
combined_data <- rbind(
participant_data,
synthetic_data_list[[1]],
synthetic_data_list[[2]],
synthetic_data_list[[3]]
)
# Simple linear regression (pooled across participants)
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans)) +
# Single global regression line in black
geom_smooth(
data = participant_data,
aes(x = colours, y = DQ_U_o_trans),
method = "lm",
inherit.aes = FALSE,
se = FALSE,
color = "black",
linewidth = 0.9
) +
# Points
geom_point(aes(x = colours, y = DQ_U_o_trans)) +
labs(
x = "colours",
y = "DQ_U_o_trans"
) +
theme_minimal()
# Simple linear regression (pooled across participants)
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans)) +
# Single global regression line in black
geom_smooth(
data = participant_data,
aes(x = colours, y = DQ_U_o_trans),
method = "lm",
inherit.aes = FALSE,
se = FALSE,
color = "black",
linewidth = 0.9
) +
# Points
geom_point(aes(x = colours, y = DQ_U_o_trans)) +
labs(
x = "colours",
y = "DQ_U_o_trans"
) +
theme_minimal()
#install.packages("brms","dplyr")
#install.packages("devtools")
#devtools::install_github("tidyverse/tidyverse")
#devtools::install_github("thomasp85/gganimate")
knitr::opts_chunk$set(echo = TRUE)
library(brms)
library(dplyr)
library(tidyverse)
library(gganimate)
library(bayesplot)
setwd("~/OneDrive - The University of Melbourne/Bayesian Updating and Complexity/Code/Analysis")
participant_data <- read.csv("participant_data.csv")
setwd("~/OneDrive - The University of Melbourne/Bayesian Updating and Complexity/Code/Analysis")
root.dir("~/OneDrive - The University of Melbourne/Bayesian Updating and Complexity/Code/Analysis")
root.dir.setwd("~/OneDrive - The University of Melbourne/Bayesian Updating and Complexity/Code/Analysis")
# Simple linear regression (pooled across participants)
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans)) +
# Single global regression line in black
geom_smooth(
data = participant_data,
aes(x = colours, y = DQ_U_o_trans),
method = "lm",
inherit.aes = FALSE,
se = FALSE,
color = "black",
linewidth = 0.9
) +
# Points
geom_point(aes(x = colours, y = DQ_U_o_trans)) +
labs(
x = "colours",
y = "DQ_U_o_trans"
) +
theme_minimal()
setwd("~/OneDrive - The University of Melbourne/Bayesian Updating and Complexity/Code/Analysis")
participant_data <- read.csv("participant_data.csv")
participant_data <- read.csv("participant_data.csv")
setwd("~/OneDrive - The University of Melbourne/Bayesian Updating and Complexity/Code/Analysis")
participant_data <- read.csv("participant_data.csv")
#install.packages("brms","dplyr")
#install.packages("devtools")
#devtools::install_github("tidyverse/tidyverse")
#devtools::install_github("thomasp85/gganimate")
knitr::opts_chunk$set(echo = TRUE)
library(brms)
library(dplyr)
library(tidyverse)
library(gganimate)
library(bayesplot)
setwd("~/OneDrive - The University of Melbourne/Bayesian Updating and Complexity/Code/Analysis")
participant_data <- read.csv("participant_data.csv")
View(participant_data)
