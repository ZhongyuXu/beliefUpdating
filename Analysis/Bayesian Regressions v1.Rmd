---
title: "Bayesian Regressions"
output: html_document
date: "2025-03-21"
---

```{r setup, include=FALSE}
#install.packages("brms","dplyr")
#install.packages("devtools")
#devtools::install_github("tidyverse/tidyverse")
#devtools::install_github("thomasp85/gganimate")

knitr::opts_chunk$set(echo = TRUE)
library(brms)
library(dplyr)
library(tidyverse)
library(gganimate)
library(bayesplot)
```

# Read Data

```{r}
setwd("~/OneDrive - The University of Melbourne/Bayesian Updating and Complexity/Code/Analysis")

participant_data <- read.csv("participant_data.csv")


```

# Transform Data


To fit Bayesian regression, it is the best practice to standardize the regressors



```{r}
n <- nrow(participant_data)
participant_data <- participant_data %>%
  mutate(
    urns_trans    = as.numeric(scale(urns)),
    colours_trans = as.numeric(scale(colours)),
    seqBall_trans = as.numeric(scale(seqBall)),
    DV_seqBall_1_trans = as.numeric(scale(DV_seqBall_1)),
    DV_seqBall_2_trans = as.numeric(scale(DV_seqBall_2)),
    DV_seqBall_3_trans = as.numeric(scale(DV_seqBall_3)),
    ACC_u_trans = as.numeric(scale(ACC_u)),
    ACC_c_trans = as.numeric(scale(ACC_c)),
    CC_u_trans = as.numeric(scale(CC_u)),
    CC_c_trans = as.numeric(scale(CC_c)),
    DQ_U_o_trans = (DQ_U_o * (n - 1) + 0.5) / n,
    DQ_C_o_trans = (DQ_C_o * (n - 1) + 0.5) / n,
    DQ_U_s_trans = (DQ_U_s * (n - 1) + 0.5) / n,
    DQ_C_s_trans = (DQ_C_s * (n - 1) + 0.5) / n,
  )
```

To fit a Beta regression, decision quality values must lie strictly between 0 and 1. We transform all decision quality values equal to 0 to 10^{-10}, and those equal to 1 to (1 - 10^{-10})

!!! Note: The method I put onto the preregistration does not converge

```{r}
# Specify the column names to transform
cols <- c("DQ_U_o", "DQ_U_s", "DQ_C_o", "DQ_C_s","DQ_U_o_trans", "DQ_U_s_trans", "DQ_C_o_trans", "DQ_C_s_trans")

# Apply the transformation to each specified column in participant_data
#participant_data[cols] <- lapply(participant_data[cols], function(x) {
 # ifelse(x == 0, 10^(-1), ifelse(x == 1, 1 - 10^(-1), x))
#})

```

# H1-B

In the state updating question, decision quality does not decrease as the number of potential signals (number of possible colors) in an instance increase, since more potential signals does not increase computational complexity.

Beta distribution requires outcomes to be strictly between 0 and 1. Even if your response is exactly 1 (or 0), it violates that assumption. A common fix is to transform the response so that values are mapped into the open interval (0,1). One popular transformation is:

y\^\* = \frac{y * (n - 1) + 0.5} {n}

where n is the number of observations. This gently "squeezes" the 0's and 1's into the interval (0,1) without distorting the data too much.

## Visualising H1-B using random intercept simple linear regressions
```{r}
# Simple linear regression (pooled across participants)
ggplot(participant_data, aes(x = colours, y = DQ_U_o_trans)) +
  # Single global regression line in black
  geom_smooth(
    data = participant_data, 
    aes(x = colours, y = DQ_U_o),
    method = "lm", 
    inherit.aes = FALSE, 
    se = FALSE, 
    color = "black", 
    linewidth = 0.9
  ) +
  # Points
  geom_point(aes(x = colours, y = DQ_U_o)) +
  labs(
    x = "colours",
    y = "DQ_U_o"
  ) +
  theme_minimal()


# Convert participantID to character in base R
participant_data$participantID <- as.character(participant_data$participantID)
# Multiple regressions by participant
ggplot(participant_data, aes(x = colours, y = DQ_U_o, color = participantID)) +
  # One regression line per participant (colored by participantID)
  geom_smooth(
    method = "lm",
    se = FALSE,
    linewidth = 0.9
  ) +
  # Points (also colored by participantID)
  geom_point() +
  labs(
    x = "colours",
    y = "DQ_U_o"
  ) +
  theme_minimal()
```
# Bayesian Regressions


```{r}
# Regression 1 - Diffuse

# Define priors for the model:
# - Fixed effects (slopes and intercept): Normal(0, 1000000)
# - Random intercept standard deviation: Half-Cauchy(0, 1)
# - Beta precision parameter (phi): Gamma(2, 0.1)
priors <- c(
  set_prior("normal(0, 1000000)", class = "b"),
  set_prior("normal(0, 1000000)", class = "Intercept"),
  set_prior("cauchy(0, 1)", class = "sd", lb = 0),
  set_prior("gamma(2, 0.1)", class = "phi")
)


# Fit the hierarchical Bayesian beta regression model using the transformed response
r1_diffuse <- brm(
  formula = DQ_U_o_trans ~ urns_trans + colours_trans + seqBall_trans + (1 | participantID),
  data = participant_data,
  family = Beta(link = "logit"),
  prior = priors,
  chains = 4,
  iter = 2000,
  warmup = 1000,
  seed = 123,
  save_pars = save_pars(all = TRUE),
  control = list(adapt_delta = 0.95)
)

r2_diffuse <- brm(
  formula = DQ_U_o_trans ~ urns_trans + seqBall_trans + (1 | participantID),
  data = participant_data,
  family = Beta(link = "logit"),
  prior = priors,
  chains = 4,
  iter = 2000,
  warmup = 1000,
  seed = 123,
  save_pars = save_pars(all = TRUE),
  control = list(adapt_delta = 0.95)
)

```



```{r}
# Plot the parameters
#print(plot(model_1))

# Diagnostic plots
library(bayesplot)
library(ggplot2)
library(dplyr)

#--------------------------------------------------
# 1. Pair Plot for Visual Diagnosis of Divergences
#--------------------------------------------------

# Convert the model's posterior draws to an array
post_array <- as.array(model_1)

# Choose a set of parameters to inspect.
# Here, we select the global intercept, slopes for your standardized predictors,
# the random intercept SD, and the precision parameter phi.
pars_to_plot <- c("b_colours_trans", 
                    "sd_participantID__Intercept", "phi")

# Create the pair plot
mcmc_pairs(post_array, pars = pars_to_plot)
# This plot will help you inspect parameter correlations and potential divergent transitions.

#--------------------------------------------------
# 2. Fitted (Predicted) vs. Observed Plot
#--------------------------------------------------

# Extract fitted values from the model
# 'fitted()' returns a matrix with the estimate, and lower/upper credible intervals.
fitted_vals <- fitted(model_1)[, "Estimate"]

# Create a data frame that pairs the fitted values with the observed values.
plot_df <- participant_data %>% 
  mutate(fitted = fitted_vals)

# Plot the observed DQ_U_o_trans vs. the fitted (predicted) values.
ggplot(plot_df, aes(x = DQ_U_o_trans, y = fitted)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Fitted vs Observed DQ_U_o_trans",
       x = "Observed DQ_U_o_trans",
       y = "Fitted (Predicted) DQ_U_o_trans") +
  theme_minimal()



# Create a parallel coordinates plot
mcmc_parcoord(
  as.matrix(model_2),
  pars = vars(-lp__),  # plot all parameters except the log posterior
  np = nuts_params(model_2),      # add sampler diagnostics
  np_style = scatter_style_np(
    div_color = "green", 
    div_size = 0.25, 
    div_alpha = 0.9
  )
) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


posterior_draws <- as.matrix(model_1)

# Extract NUTS sampler diagnostics (for identifying divergences, etc.)
nuts_info <- nuts_params(model_1)

# Example: Bivariate scatter of the slopes for 'urns_trans' and 'colours_trans'
mcmc_scatter(
  posterior_draws,
  pars = vars(contains("urns_trans"), contains("colours_trans")),
  np = nuts_info,
  np_style = scatter_style_np(
    div_color = "green",  # color for divergent points
    div_size = 0.15,
    div_alpha = 0.4
  )
) +
  labs(
    x = "Slope for urns_trans",
    y = "Slope for colours_trans"
  )
```



```{r}
# Posterior predictive checks to evaluate model fit}
#print(pp_check(model_1))
```


```{r}
# Regression 2

# Fit the hierarchical Bayesian beta regression model using the transformed response


```

```{r}
# Diagnostic plots
#print(plot(model_2))
```

```{r}
# Posterior predictive checks to evaluate model fit}
#print(pp_check(model_2))
```

```{r}

```

## Add Random Slope

```{r}
random_slope_model_1 <- brm(
  formula = DQ_U_o_trans ~ urns_trans + colours_trans + seqBall_trans + (1 + urns + colours + seqBall | participantID),
  data = participant_data,
  family = Beta(link = "logit"),
  prior = priors,
  chains = 4,
  iter = 2000,
  warmup = 1000,
  #cores = 4,
  seed = 123,
  save_pars = save_pars(all = TRUE),
  control = list(adapt_delta = 0.95)
)

random_slope_model_2 <- brm(
  formula = DQ_U_o_trans ~ urns_trans + seqBall_trans + (1 + urns + seqBall | participantID),
  data = participant_data,
  family = Beta(link = "logit"),
  prior = priors,
  chains = 4,
  iter = 2000,
  warmup = 1000,
  #cores = 4,
  seed = 123,
  save_pars = save_pars(all = TRUE),
  control = list(adapt_delta = 0.95)
)
```

```{r}
#print(plot(random_slope_model_1))
#print(plot(random_slope_model_2))
```

```{r}

# Display a summary of the fitted model
print(summary(r1_diffuse))
print(summary(r2_diffuse))

# Compute marginal likelihoods via bridgesampling for each model
bridge_1 <- bridge_sampler(r1_diffuse)
bridge_2 <- bridge_sampler(r2_diffuse)

# Calculate the Bayes factor (BF) comparing Model A to Model B.
# BF_21 > 3
bf_value_1 <- bridgesampling::bf(bridge_2, bridge_1)
print(bf_value_1)

#bf_value_2 <- bridgesampling::bf(bridge_1, bridge_2)
#print(bf_value_2)



print(summary(random_slope_model_1))
print(summary(random_slope_model_2))
# Compute marginal likelihoods via bridgesampling for each model
bridge_1_rs <- bridge_sampler(random_slope_model_1)
bridge_2_rs <- bridge_sampler(random_slope_model_2)

# Calculate the Bayes factor (BF) comparing Model A to Model B.
# BF_21 > 3
bf_value_rs_1 <- bridgesampling::bf(bridge_2_rs, bridge_1_rs)
print(bf_value_rs_1)

#bf_value_rs_2 <- bridgesampling::bf(bridge_1_rs, bridge_2_rs)
#print(bf_value_rs_2)
```
```{r}
print(bf_value_1)
if (bf_value_1[1] > 3) {
  print("Random Intercept Model Support H1-B")
} else {
  print("Random Intercept Model Does not Support H1-B")
}

print(bf_value_rs_1)
if (bf_value_rs_1[1] > 3) {
  print("Random Intercept and Slope Model Support H1-B")
} else {
  print("Random Intercept and Slope Model Does not Support H1-B")
}
```




























