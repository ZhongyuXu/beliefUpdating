@misc{bell-garrisonExploringParallelsHuman2016,
  title = {Exploring {{Parallels Between Human And Animal Decision-Making}}},
  author = {{Bell-Garrison}, Daniel},
  year = {2016},
  month = sep,
  journal = {The Decision Lab},
  urldate = {2021-10-19},
  abstract = {How do animals make choices, and is their decision-making process anything like that of humans?},
  langid = {canadian},
  file = {/Users/zhongyux/Zotero/storage/CZE5RW35/parallels-between-human-animal-decision-making.html}
}

@article{dayanDecisionTheoryReinforcement2008,
  title = {Decision Theory, Reinforcement Learning, and the Brain},
  author = {Dayan, P. and Daw, N. D.},
  year = {2008},
  month = dec,
  journal = {Cognitive, Affective, \& Behavioral Neuroscience},
  volume = {8},
  number = {4},
  pages = {429--453},
  issn = {1530-7026, 1531-135X},
  doi = {10.3758/CABN.8.4.429},
  urldate = {2021-09-22},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/H2EDAB5E/Dayan and Daw - 2008 - Decision theory, reinforcement learning, and the b.pdf}
}

@techreport{lopez-yepezNormativeAccountChoice2020,
  type = {Preprint},
  title = {A Normative Account of Choice History Effects in Mice and Humans},
  author = {{Lopez-Yepez}, Junior Samuel and Martin, Juliane and Hulme, Oliver and Kvitsiani, Duda},
  year = {2020},
  month = jul,
  institution = {Neuroscience},
  doi = {10.1101/2020.07.22.216234},
  urldate = {2021-09-22},
  abstract = {Abstract           Choice history effects describe how future choices depend on the history of past choices. Choice history effects are typically framed as a bias rather than an adaptive phenomenon because the phenomenon generally degrades reward rates in experimental tasks. How-ever, in natural habitats, choices made in the past constrain choices that can be made in the future. For foraging animals, the probability of obtaining a reward in a given patch depends on the degree to which the animals have exploited the patch in the past. One problem with many experimental tasks that show choice history effects is that such tasks artificially decouple choice history from its consequences in regard to reward availability over time. To circumvent this, we used a variable interval (VI) reward schedule that reinstates a more natural contingency between past choices and future reward availability. By manipulating first- and second-order statistics of the environment, we dissociated choice history, reward history, and reaction times. We found that choice history effects reflect the growth rate of the reward probability of the unchosen option, reward history effects reflect environmental volatility, and reaction time reflects overall reward rate. By testing in mice and humans, we show that the same choice history effects can be generalized across species and that these effects are similar to those observed in optimal agents. Furthermore, we develop a new reinforcement learning model that explicitly incorporates choice history over multiple timescales into the decision process, and we examine its predictive adequacy in accounting for the associated behavioral data. We show that this new variant, known as the double trace model, has a higher predictive adequacy of choice data, in addition to better reward harvesting efficiency in simulated environments. Finally, we show that the choice history effects emerge in optimal models of foraging in habitats with diminishing returns, thus linking this phenomenon to a wider class of optimality models in behavioral ecology. These results suggests that choice history effects may be adaptive for natural contingencies between consumption and reward availability. This concept lends credence to a normative account of choice history effects that extends beyond its description as a bias.},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/VB7YP75E/Lopez-Yepez et al. - 2020 - A normative account of choice history effects in m.pdf}
}

@article{charpentierReinforcementLearningEconomics2020,
  title = {Reinforcement {{Learning}} in {{Economics}} and {{Finance}}},
  author = {Charpentier, Arthur and Elie, Romuald and Remlinger, Carl},
  year = {2020},
  month = mar,
  journal = {arXiv:2003.10014 [cs, econ, q-fin]},
  eprint = {2003.10014},
  primaryclass = {cs, econ, q-fin},
  urldate = {2021-09-22},
  abstract = {Reinforcement learning algorithms describe how an agent can learn an optimal action policy in a sequential decision process, through repeated experience. In a given environment, the agent policy provides him some running and terminal rewards. As in online learning, the agent learns sequentially. As in multi-armed bandit problems, when an agent picks an action, he can not infer ex-post the rewards induced by other action choices. In reinforcement learning, his actions have consequences: they influence not only rewards, but also future states of the world. The goal of reinforcement learning is to find an optimal policy -- a mapping from the states of the world to the set of actions, in order to maximize cumulative reward, which is a long term strategy. Exploring might be sub-optimal on a short-term horizon but could lead to optimal long-term ones. Many problems of optimal control, popular in economics for more than forty years, can be expressed in the reinforcement learning framework, and recent advances in computational science, provided in particular by deep learning algorithms, can be used by economists in order to solve complex behavioral problems. In this article, we propose a state-of-the-art of reinforcement learning techniques, and present applications in economics, game theory, operation research and finance.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Economics - Theoretical Economics,Quantitative Finance - Computational Finance},
  file = {/Users/zhongyux/Zotero/storage/MRTZXAZ5/Charpentier et al. - 2020 - Reinforcement Learning in Economics and Finance.pdf}
}

@article{charnessWhenOptimalChoices2005,
  title = {When {{Optimal Choices Feel Wrong}}: {{A Laboratory Study}} of {{Bayesian Updating}}, {{Complexity}}, and {{Affect}}},
  shorttitle = {When {{Optimal Choices Feel Wrong}}},
  author = {Charness, Gary and Levin, Dan},
  year = {2005},
  month = aug,
  journal = {American Economic Review},
  volume = {95},
  number = {4},
  pages = {1300--1309},
  issn = {0002-8282},
  doi = {10.1257/0002828054825583},
  urldate = {2023-12-01},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/CEUZZI8S/Charness and Levin - 2005 - When Optimal Choices Feel Wrong A Laboratory Stud.pdf}
}

@article{j.valoneAreAnimalsCapable2006,
  title = {Are Animals Capable of {{Bayesian}} Updating? {{An}} Empirical Review},
  shorttitle = {Are Animals Capable of {{Bayesian}} Updating?},
  author = {J. Valone, Thomas},
  year = {2006},
  journal = {Oikos},
  volume = {112},
  number = {2},
  pages = {252--259},
  issn = {1600-0706},
  doi = {10.1111/j.0030-1299.2006.13465.x},
  urldate = {2023-12-01},
  abstract = {Numerous behavioral models assume individuals combine knowledge in the form of a prior distribution with current sample information using Bayesian updating to estimate the quality of environmental parameters. I examine this assumption by reviewing 11 empirical studies. Six studies compared observed behavior to predictions of Bayesian and non-Bayesian models, while five studies manipulated prior distributions directly and observed how such manipulations altered behavior. Eight species of birds, three mammals, one fish and one insect exhibited behavior consistent with Bayesian updating models; one studied bird species failed to show evidence of Bayesian updating. Most studies examined how individuals estimated food patch quality but two investigated mating decisions. These studies suggest a variety of animals in different ecological contexts behave in manners consistent with predictions of Bayesian updating models. Future work on decision-making should focus on understanding how animals learn prior distributions and on decision-making in additional ecological contexts.},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/NI599VAY/J. Valone - 2006 - Are animals capable of Bayesian updating An empir.pdf;/Users/zhongyux/Zotero/storage/BGCI9K5R/j.0030-1299.2006.13465.html}
}

@article{kwisthoutComputationalResourceDemands2020,
  title = {Computational {{Resource Demands}} of a {{Predictive Bayesian Brain}}},
  author = {Kwisthout, Johan and Van Rooij, Iris},
  year = {2020},
  month = jun,
  journal = {Computational Brain \& Behavior},
  volume = {3},
  number = {2},
  pages = {174--188},
  issn = {2522-0861, 2522-087X},
  doi = {10.1007/s42113-019-00032-3},
  urldate = {2024-02-02},
  abstract = {There is a growing body of evidence that the human brain may be organized according to principles of predictive processing. An important conjecture in neuroscience is that a brain organized in this way can effectively and efficiently approximate Bayesian inferences. Given that many forms of cognition seem to be well characterized as a form of Bayesian inference, this conjecture has great import for cognitive science. It suggests that predictive processing may provide a neurally plausible account of how forms of cognition that are modeled as Bayesian inference may be physically implemented in the brain. Yet, as we show in this paper, the jury is still out on whether or not the conjecture is really true. Specifically, we demonstrate that each key subcomputation invoked in predictive processing potentially hides a computationally intractable problem. We discuss the implications of these sobering results for the predictive processing account and propose a way to move forward.},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/E23E9RQ9/Kwisthout and Van Rooij - 2020 - Computational Resource Demands of a Predictive Bay.pdf}
}

@article{alos-ferrerPartTimeBayesiansIncentives2023,
  title = {Part-{{Time Bayesians}}: {{Incentives}} and {{Behavioral Heterogeneity}} in {{Belief Updating}}},
  shorttitle = {Part-{{Time Bayesians}}},
  author = {{Al{\'o}s-Ferrer}, Carlos and Garagnani, Michele},
  year = {2023},
  month = sep,
  journal = {Management Science},
  volume = {69},
  number = {9},
  pages = {5523--5542},
  issn = {0025-1909, 1526-5501},
  doi = {10.1287/mnsc.2022.4584},
  urldate = {2024-02-02},
  abstract = {Decisions in management and finance rely on information that often includes winlose feedback (e.g., gains and losses, success and failure). Simple reinforcement then suggests to blindly repeat choices if they led to success in the past and change them otherwise, which might conflict with Bayesian updating of beliefs. We use finite mixture models and hidden Markov models, adapted from machine learning, to uncover behavioral heterogeneity in the reliance on difference behavioral rules across and within individuals in a belief-updating experiment. Most decision makers rely both on Bayesian updating and reinforcement. Para\- doxically, an increase in incentives increases the reliance on reinforcement because the winlose cues become more salient.},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/7C5RS3S5/Alós-Ferrer and Garagnani - 2023 - Part-Time Bayesians Incentives and Behavioral Het.pdf}
}

@techreport{zhuComputationLimitedBayesianUpdating2023,
  type = {Preprint},
  title = {Computation-{{Limited Bayesian Updating}}},
  author = {Zhu, Jian-Qiao and Sanborn, Adam N and Chater, Nick and Griffiths, Thomas L.},
  year = {2023},
  month = jan,
  institution = {PsyArXiv},
  doi = {10.31234/osf.io/znywg},
  urldate = {2024-03-06},
  abstract = {Effectively updating one's beliefs requires sufficient empirical evidence (i.e., data) and the computational capacity to process it. Yet both data and computational resources are limited for human minds. Here, we study the problem of belief updating under limited data and limited computation. Using information theory to characterize constraints on computation, we find that the solution to the resulting optimization problem links the data and computational limitations together: when computational resources are tight, agents may not be able to integrate new empirical evidence. The resource-rational belief updating rule we identify offers a novel interpretation of conservative Bayesian updating.},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/NFHDHTD4/Zhu et al. - 2023 - Computation-Limited Bayesian Updating.pdf}
}

@article{francoHarnessingComputationalComplexity2023,
  title = {Harnessing {{Computational Complexity Theory}} to {{Model Human Decision-making}} and {{Cognition}}},
  author = {Franco, Juan Pablo and Murawski, Carsten},
  year = {2023},
  journal = {Cognitive Science},
  volume = {47},
  number = {6},
  pages = {e13304},
  issn = {1551-6709},
  doi = {10.1111/cogs.13304},
  urldate = {2023-07-03},
  abstract = {A central aim of cognitive science is to understand the fundamental mechanisms that enable humans to navigate and make sense of complex environments. In this letter, we argue that computational complexity theory, a foundational framework for evaluating computational resource requirements, holds significant potential in addressing this challenge. As humans possess limited cognitive resources for processing vast amounts of information, understanding how humans perform complex cognitive tasks requires comprehending the underlying factors that drive information processing demands. Computational complexity theory provides a comprehensive theoretical framework to achieve this goal. By adopting this framework, we can gain new insights into how cognitive systems work and develop a more nuanced understanding of the relation between task complexity and human behavior. We provide empirical evidence supporting our argument and identify several open research questions and challenges in applying computational complexity theory to human decision-making and cognitive science at large.},
  copyright = {{\copyright} 2023 Cognitive Science Society LLC.},
  langid = {english},
  keywords = {Behavior,cbmm,complexity,Computational complexity,Decision-making,Problem-solving,tier1,Tractable cognition},
  file = {/Users/zhongyux/Zotero/storage/K6HVAJ7D/Franco and Murawski - 2023 - Harnessing Computational Complexity Theory to Mode.pdf}
}

@article{bossaertsComputationalComplexityHuman2017,
  title = {Computational {{Complexity}} and {{Human Decision-Making}}},
  author = {Bossaerts, Peter and Murawski, Carsten},
  year = {2017},
  month = dec,
  journal = {Trends in Cognitive Sciences},
  volume = {21},
  number = {12},
  pages = {917--929},
  issn = {1879-307X},
  doi = {10.1016/j.tics.2017.09.005},
  abstract = {The rationality principle postulates that decision-makers always choose the best action available to them. It underlies most modern theories of decision-making. The principle does not take into account the difficulty of finding the best option. Here, we propose that computational complexity theory (CCT) provides a framework for defining and quantifying the difficulty of decisions. We review evidence showing that human decision-making is affected by computational complexity. Building on this evidence, we argue that most models of decision-making, and metacognition, are intractable from a computational perspective. To be plausible, future theories of decision-making will need to take into account both the resources required for implementing the computations implied by the theory, and the resource constraints imposed on the decision-maker by biology.},
  langid = {english},
  pmid = {29149998},
  keywords = {artificial intelligence,cbmm,complexity,computational modelling,Computer Simulation,Decision Making,Humans,metacognition,Metacognition,rationality,tier1},
  file = {/Users/zhongyux/Zotero/storage/BXXAZ4FM/Bossaerts and Murawski - 2017 - Computational Complexity and Human Decision-Making.pdf}
}

@article{knillBayesianBrainRole2004,
  title = {The {{Bayesian}} Brain: The Role of Uncertainty in Neural Coding and Computation},
  shorttitle = {The {{Bayesian}} Brain},
  author = {Knill, David C. and Pouget, Alexandre},
  year = {2004},
  month = dec,
  journal = {Trends in Neurosciences},
  volume = {27},
  number = {12},
  pages = {712--719},
  issn = {0166-2236},
  doi = {10.1016/j.tins.2004.10.007},
  urldate = {2024-04-14},
  abstract = {To use sensory information efficiently to make judgments and guide action in the world, the brain must represent and use information about uncertainty in its computations for perception and action. Bayesian methods have proven successful in building computational theories for perception and sensorimotor control, and psychophysics is providing a growing body of evidence that human perceptual computations are `Bayes' optimal'. This leads to the `Bayesian coding hypothesis': that the brain represents sensory information probabilistically, in the form of probability distributions. Several computational schemes have recently been proposed for how this might be achieved in populations of neurons. Neurophysiological data on the hypothesis, however, is almost non-existent. A major challenge for neuroscientists is to test these ideas experimentally, and so determine whether and how neurons code information about sensory uncertainty.}
}

@book{doyaBayesianBrainProbabilistic2007,
  title = {Bayesian {{Brain}}: {{Probabilistic Approaches}} to {{Neural Coding}}},
  shorttitle = {Bayesian {{Brain}}},
  author = {Doya, Kenji},
  year = {2007},
  publisher = {MIT Press},
  abstract = {A Bayesian approach can contribute to an understanding of the brain on multiple levels, by giving normative predictions about how an ideal sensory system should combine prior knowledge and observation, by providing mechanistic interpretation of the dynamic functioning of the brain circuit, and by suggesting optimal ways of deciphering experimental data. Bayesian Brain brings together contributions from both experimental and theoretical neuroscientists that examine the brain mechanisms of perception, decision making, and motor control according to the concepts of Bayesian estimation.After an overview of the mathematical concepts, including Bayes' theorem, that are basic to understanding the approaches discussed, contributors discuss how Bayesian concepts can be used for interpretation of such neurobiological data as neural spikes and functional brain imaging. Next, contributors examine the modeling of sensory processing, including the neural coding of information about the outside world. Finally, contributors explore dynamic processes for proper behaviors, including the mathematics of the speed and accuracy of perceptual decisions and neural models of belief propagation.},
  googlebooks = {bsQMWXXHzrYC},
  isbn = {978-0-262-04238-3},
  langid = {english},
  keywords = {Mathematics / Probability & Statistics / Bayesian Analysis,Medical / Internal Medicine,Medical / Neurology,Medical / Neuroscience}
}

@article{wieseJakobHohwyPredictive2014,
  title = {Jakob {{Hohwy}}: {{The Predictive Mind}}},
  shorttitle = {Jakob {{Hohwy}}},
  author = {Wiese, Wanja},
  year = {2014},
  month = may,
  journal = {Minds and Machines},
  volume = {24},
  number = {2},
  pages = {233--237},
  issn = {1572-8641},
  doi = {10.1007/s11023-014-9338-6},
  urldate = {2024-04-14},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/VX49SXNQ/Wiese - 2014 - Jakob Hohwy The Predictive Mind.pdf}
}

@article{clarkWhateverNextPredictive2013,
  title = {Whatever next? {{Predictive}} Brains, Situated Agents, and the Future of Cognitive Science},
  shorttitle = {Whatever Next?},
  author = {Clark, Andy},
  year = {2013},
  month = jun,
  journal = {Behavioral and Brain Sciences},
  volume = {36},
  number = {3},
  pages = {181--204},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X12000477},
  urldate = {2024-04-14},
  abstract = {Brains, it has recently been argued, are essentially prediction machines. They are bundles of cells that support perception and action by constantly attempting to match incoming sensory inputs with top-down expectations or predictions. This is achieved using a hierarchical generative model that aims to minimize prediction error within a bidirectional cascade of cortical processing. Such accounts offer a unifying model of perception and action, illuminate the functional role of attention, and may neatly capture the special contribution of cortical processing to adaptive success. This target article critically examines this ``hierarchical prediction machine'' approach, concluding that it offers the best clue yet to the shape of a unified science of mind and action. Sections 1 and 2 lay out the key elements and implications of the approach. Section 3 explores a variety of pitfalls and challenges, spanning the evidential, the methodological, and the more properly conceptual. The paper ends (sections 4 and 5) by asking how such approaches might impact our more general vision of mind, experience, and agency.},
  langid = {english},
  keywords = {action,attention,Bayesian brain,expectation,generative model,hierarchy,perception,precision,prediction,prediction error,predictive coding,top-down processing},
  file = {/Users/zhongyux/Zotero/storage/QGWAHLN9/Clark - 2013 - Whatever next Predictive brains, situated agents,.pdf}
}

@article{leeHierarchicalBayesianInference2003,
  title = {Hierarchical {{Bayesian}} Inference in the Visual Cortex},
  author = {Lee, Tai Sing and Mumford, David},
  year = {2003},
  month = jul,
  journal = {JOSA A},
  volume = {20},
  number = {7},
  pages = {1434--1448},
  publisher = {Optica Publishing Group},
  issn = {1520-8532},
  doi = {10.1364/JOSAA.20.001434},
  urldate = {2024-04-14},
  abstract = {Traditional views of visual processing suggest that early visual neurons in areas V1 and V2 are static spatiotemporal filters that extract local features from a visual scene. The extracted information is then channeled through a feedforward chain of modules in successively higher visual areas for further analysis. Recent electrophysiological recordings from early visual neurons in awake behaving monkeys reveal that there are many levels of complexity in the information processing of the early visual cortex, as seen in the long-latency responses of its neurons. These new findings suggest that activity in the early visual cortex is tightly coupled and highly interactive with the rest of the visual system. They lead us to propose a new theoretical setting based on the mathematical framework of hierarchical Bayesian inference for reasoning about the visual system. In this framework, the recurrent feedforward/feedback loops in the cortex serve to integrate top-down contextual priors and bottom-up observations so as to implement concurrent probabilistic inference along the visual hierarchy. We suggest that the algorithms of particle filtering and Bayesian-belief propagation might model these interactive cortical computations. We review some recent neurophysiological evidences that support the plausibility of these ideas.},
  copyright = {{\copyright} 2003 Optical Society of America},
  langid = {english},
  keywords = {Edge detection,Information processing,Machine vision,Neural networks,Physiology,Spatial resolution},
  file = {/Users/zhongyux/Zotero/storage/3DJWTIJ6/Lee and Mumford - 2003 - Hierarchical Bayesian inference in the visual cort.pdf}
}

@book{oaksfordBayesianRationalityProbabilistic2007,
  title = {Bayesian {{Rationality}}: {{The Probabilistic Approach}} to {{Human Reasoning}}},
  shorttitle = {Bayesian {{Rationality}}},
  author = {Oaksford, Mike and Chater, Nick},
  year = {2007},
  month = feb,
  publisher = {OUP Oxford},
  abstract = {Are people rational? This question was central to Greek thought; and has been at the heart of psychology, philosophy, rational choice in social sciences, and probabilistic approaches to artificial intelligence. This book provides a radical re-appraisal of conventional wisdom in the psychology of reasoning.  For almost two and a half thousand years, the Western conception of what it is to be a human being has been dominated by the idea that the mind is the seat of reason - humans are, almost by definition, the rational animal. From Aristotle to the present day, rationality has been explained by comparison to systems of logic, which distinguish valid (i.e., rationally justified) from invalid arguments. Within psychology and cognitive science, such a logicist conception of the mind was adopted wholeheartedly from Piaget onwards. Simultaneous with the construction of the logicist program in cognition, other researchers found that people appeared surprisingly and systematically illogical in some experiments. Proposals within the logicist paradigm suggested that these were mere performance errors, although in some reasoning tasks only as few as 5\% of people's reasoning was logically correct.  In this book a more radical suggestion for explaining these puzzling aspects of human reasoning is put forward: the Western conception of the mind as a logical system is flawed at the very outset. The human mind is primarily concerned with practical action in the face of a profoundly complex and uncertain world. Oaksford and Chater argue that cognition should be understood in terms of probability theory, the calculus of uncertain reasoning, rather than in terms of logic, the calculus of certain reasoning. Thus, the logical mind should be replaced by the probabilistic mind - people may possess not logical rationality, but Bayesian rationality.},
  googlebooks = {sLetNgiU7ugC},
  isbn = {978-0-19-852449-6},
  langid = {english},
  keywords = {Philosophy / Logic,Philosophy / Mind & Body,Psychology / Cognitive Psychology & Cognition,Psychology / Experimental Psychology}
}

@article{fristonFreeenergyPrincipleUnified2010,
  title = {The Free-Energy Principle: A Unified Brain Theory?},
  shorttitle = {The Free-Energy Principle},
  author = {Friston, Karl},
  year = {2010},
  month = feb,
  journal = {Nature Reviews Neuroscience},
  volume = {11},
  number = {2},
  pages = {127--138},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn2787},
  urldate = {2024-04-14},
  abstract = {Adaptive agents must occupy a limited repertoire of states and therefore minimize the long-term average of surprise associated with sensory exchanges with the world. Minimizing surprise enables them to resist a natural tendency to disorder.Surprise rests on predictions about sensations, which depend on an internal generative model of the world. Although surprise cannot be measured directly, a free-energy bound on surprise can be, suggesting that agents minimize free energy by changing their predictions (perception) or by changing the predicted sensory inputs (action).Perception optimizes predictions by minimizing free energy with respect to synaptic activity (perceptual inference), efficacy (learning and memory) and gain (attention and salience). This furnishes Bayes-optimal (probabilistic) representations of what caused sensations (providing a link to the Bayesian brain hypothesis).Bayes-optimal perception is mathematically equivalent to predictive coding and maximizing the mutual information between sensations and the representations of their causes. This is a probabilistic generalization of the principle of efficient coding (the infomax principle) or the minimum-redundancy principle.Learning under the free-energy principle can be formulated in terms of optimizing the connection strengths in hierarchical models of the sensorium. This rests on associative plasticity to encode causal regularities and appeals to the same synaptic mechanisms as those underlying cell assembly formation.Action under the free-energy principle reduces to suppressing sensory prediction errors that depend on predicted (expected or desired) movement trajectories. This provides a simple account of motor control, in which action is enslaved by perceptual (proprioceptive) predictions.Perceptual predictions rest on prior expectations about the trajectory or movement through the agent's state space. These priors can be acquired (as empirical priors during hierarchical inference) or they can be innate (epigenetic) and therefore subject to selective pressure.Predicted motion or state transitions realized by action correspond to policies in optimal control theory and reinforcement learning. In this context, value is inversely proportional to surprise (and implicitly free energy), and rewards correspond to innate priors that constrain policies.},
  copyright = {2010 Springer Nature Limited},
  langid = {english},
  keywords = {Control theory,Neural encoding},
  file = {/Users/zhongyux/Zotero/storage/7ZJEDYU3/Friston - 2010 - The free-energy principle a unified brain theory.pdf}
}

@article{tenenbaumHowGrowMind2011,
  title = {How to {{Grow}} a {{Mind}}: {{Statistics}}, {{Structure}}, and {{Abstraction}}},
  shorttitle = {How to {{Grow}} a {{Mind}}},
  author = {Tenenbaum, Joshua B. and Kemp, Charles and Griffiths, Thomas L. and Goodman, Noah D.},
  year = {2011},
  month = mar,
  journal = {Science},
  volume = {331},
  number = {6022},
  pages = {1279--1285},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1192788},
  urldate = {2024-04-14},
  abstract = {In coming to understand the world---in learning concepts, acquiring language, and grasping causal relations---our minds make inferences that appear to go far beyond the data available. How do we do it? This review describes recent approaches to reverse-engineering human learning and cognitive development and, in parallel, engineering more humanlike machine learning systems. Computational models that perform probabilistic inference over hierarchies of flexibly structured representations can address some of the deepest questions about the nature and origins of human thought: How does abstract knowledge guide learning and reasoning from sparse data? What forms does our knowledge take, across different domains and tasks? And how is that abstract knowledge itself acquired?},
  file = {/Users/zhongyux/Zotero/storage/99UN5FWP/Tenenbaum et al. - 2011 - How to Grow a Mind Statistics, Structure, and Abs.pdf}
}

@article{barrettTheoryConstructedEmotion2017,
  title = {The Theory of Constructed Emotion: An Active Inference Account of Interoception and Categorization},
  shorttitle = {The Theory of Constructed Emotion},
  author = {Barrett, Lisa Feldman},
  year = {2017},
  month = jan,
  journal = {Social Cognitive and Affective Neuroscience},
  volume = {12},
  number = {1},
  pages = {1--23},
  issn = {1749-5016},
  doi = {10.1093/scan/nsw154},
  urldate = {2024-04-14},
  abstract = {The science of emotion has been using folk psychology categories derived from philosophy to search for the brain basis of emotion. The last two decades of neuroscience research have brought us to the brink of a paradigm shift in understanding the workings of the brain, however, setting the stage to revolutionize our understanding of what emotions are and how they work. In this article, we begin with the structure and function of the brain, and from there deduce what the biological basis of emotions might be. The answer is a brain-based, computational account called the theory of constructed emotion.},
  file = {/Users/zhongyux/Zotero/storage/JJFDQTEG/Barrett - 2017 - The theory of constructed emotion an active infer.pdf}
}

@article{francoTaskindependentMetricsComputational2022,
  title = {Task-Independent Metrics of Computational Hardness Predict Human Cognitive Performance},
  author = {Franco, Juan Pablo and Doroc, Karlo and Yadav, Nitin and Bossaerts, Peter and Murawski, Carsten},
  year = {2022},
  month = jul,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {12914},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-16565-w},
  urldate = {2023-07-03},
  abstract = {The survival of human organisms depends on our ability to solve complex tasks in the face of limited cognitive resources. However, little is known about the factors that drive the complexity of those tasks. Here, building on insights from computational complexity theory, we quantify the computational hardness of cognitive tasks using a set of task-independent metrics related to the computational resource requirements of individual instances of a task. We then examine the relation between those metrics and human behavior and find that they predict both time spent on a task as well as accuracy in three canonical cognitive tasks. Our findings demonstrate that performance in cognitive tasks can be predicted based on generic metrics of their inherent computational hardness.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {cbmm,Cognitive neuroscience,complexity,Human behaviour,tier1},
  file = {/Users/zhongyux/Zotero/storage/U2LQGJV3/Franco et al. - 2022 - Task-independent metrics of computational hardness.pdf}
}

@article{colmanCooperationPsychologicalGame2003,
  title = {Cooperation, Psychological Game Theory, and Limitations of Rationality in Social Interaction},
  author = {Colman, Andrew M.},
  year = {2003},
  month = apr,
  journal = {Behavioral and Brain Sciences},
  volume = {26},
  number = {2},
  pages = {139--153},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X03000050},
  urldate = {2024-04-14},
  abstract = {Rational choice theory enjoys unprecedented popularity and influence in the behavioral and social sciences, but it generates intractable problems when applied to socially interactive decisions. In individual decisions, instrumental rationality is defined in terms of expected utility maximization. This becomes problematic in interactive decisions, when individuals have only partial control over the outcomes, because expected utility maximization is undefined in the absence of assumptions about how the other participants will behave. Game theory therefore incorporates not only rationality but also common knowledge assumptions, enabling players to anticipate their co-players' strategies. Under these assumptions, disparate anomalies emerge. Instrumental rationality, conventionally interpreted, fails to explain intuitively obvious features of human interaction, yields predictions starkly at variance with experimental findings, and breaks down completely in certain cases. In particular, focal point selection in pure coordination games is inexplicable, though it is easily achieved in practice; the intuitively compelling payoff-dominance principle lacks rational justification; rationality in social dilemmas is self-defeating; a key solution concept for cooperative coalition games is frequently inapplicable; and rational choice in certain sequential games generates contradictions. In experiments, human players behave more cooperatively and receive higher payoffs than strict rationality would permit. Orthodox conceptions of rationality are evidently internally deficient and inadequate for explaining human interaction. Psychological game theory, based on nonstandard assumptions, is required to solve these problems, and some suggestions along these lines have already been put forward.},
  langid = {english},
  keywords = {backward induction,Centipede game,common knowledge,cooperation,epistemic reasoning,game theory,payoff dominance,pure coordination game,rational choice theory,social dilemma},
  file = {/Users/zhongyux/Zotero/storage/F4I6QC2R/Colman - 2003 - Cooperation, psychological game theory, and limita.pdf}
}

@article{turingComputingMachineryIntelligence1950,
  title = {Computing {{Machinery}} and {{Intelligence}}},
  author = {Turing, A. M.},
  year = {1950},
  journal = {Mind},
  volume = {59},
  number = {236},
  eprint = {2251299},
  eprinttype = {jstor},
  pages = {433--460},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/EUWAZILK/Turing - 1950 - Computing Machinery and Intelligence.pdf}
}

@article{kwisthoutBridgingGapTheory2013,
  title = {Bridging the Gap between Theory and Practice of Approximate {{Bayesian}} Inference},
  author = {Kwisthout, Johan and {van Rooij}, Iris},
  year = {2013},
  month = sep,
  journal = {Cognitive Systems Research},
  series = {Cognitive {{Systems Research}}:{{Special Issue}} on {{ICCM2012}}},
  volume = {24},
  pages = {2--8},
  issn = {1389-0417},
  doi = {10.1016/j.cogsys.2012.12.008},
  urldate = {2024-05-21},
  abstract = {In computational cognitive science, many cognitive processes seem to be successfully modeled as Bayesian computations. Yet, many such Bayesian computations have been proven to be computationally intractable (NP-hard) for unconstrained input domains, even if only an approximate solution is sought. This computational complexity result seems to be in strong contrast with the ease and speed with which humans can typically make the inferences that are modeled by Bayesian models. This contrast---between theory and practice---poses a considerable theoretical challenge for computational cognitive modelers: How can intractable Bayesian computations be transformed into computationally plausible `approximate' models of human cognition? In this paper, three candidate notions of `approximation' are discussed, each of which has been suggested in the cognitive science literature. We will sketch how (parameterized) computational complexity analyses can yield model variants that are tractable and which can serve as the basis of computationally plausible models of cognition.},
  keywords = {Algorithms,Approximation,Bayesian inference,Computational explanation,NP-hard,Parameterized complexity theory},
  file = {/Users/zhongyux/Zotero/storage/QZR49EUW/Kwisthout and van Rooij - 2013 - Bridging the gap between theory and practice of ap.pdf}
}

@article{kwisthoutTreeWidthComputationalComplexity2015,
  title = {Tree-{{Width}} and the {{Computational Complexity}} of {{MAP Approximations}} in {{Bayesian Networks}}},
  author = {Kwisthout, Johan},
  year = {2015},
  month = aug,
  journal = {Journal of Artificial Intelligence Research},
  volume = {53},
  pages = {699--720},
  issn = {1076-9757},
  doi = {10.1613/jair.4794},
  urldate = {2024-05-21},
  abstract = {The problem of finding the most probable explanation to a designated set of variables given partial evidence (the MAP problem) is a notoriously intractable problem in Bayesian networks, both to compute exactly and to approximate. It is known, both from theoretical considerations and from practical experience, that low tree-width is typically an essential prerequisite to efficient exact computations in Bayesian networks. In this paper we investigate whether the same holds for approximating MAP. We define four notions of approximating MAP (by value, structure, rank, and expectation) and argue that all of them are intractable in general. We prove that efficient value-approximations, structure-approximations, and rank-approximations of MAP instances with high tree-width will violate the Exponential Time Hypothesis. In contrast, we show that MAP can sometimes be efficiently expectation-approximated, even in instances with high tree-width, if the most probable explanation has a high probability. We introduce the complexity class FERT, analogous to the class FTP, to capture this notion of fixed-parameter expectation-approximability. We suggest a road-map to future research that yields fixed-parameter tractable results for expectation-approximate MAP, even in graphs with high tree-width.},
  copyright = {Copyright (c)},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/J2QGJ4WK/Kwisthout - 2015 - Tree-Width and the Computational Complexity of MAP.pdf}
}

@article{gretherTestingBayesRule1992,
  title = {Testing Bayes Rule and the Representativeness Heuristic: {{Some}} Experimental Evidence},
  shorttitle = {Testing Bayes Rule and the Representativeness Heuristic},
  author = {Grether, David M.},
  year = {1992},
  month = jan,
  journal = {Journal of Economic Behavior \& Organization},
  volume = {17},
  number = {1},
  pages = {31--57},
  issn = {0167-2681},
  doi = {10.1016/0167-2681(92)90078-P},
  urldate = {2024-05-21},
  abstract = {The psychological literature has identified a number of heuristics which individuals may use in making judgements or choices under uncertainty. Mathematically equivalent problems may be treated differently depending upon details of the decision setting. The results presented in this paper are consistent with those findings. In equivalent problems subjects appear to adopt different strategies in response to observing different data. Some experiments included financial incentives for accuracy and some did not. The majority of subjects in both treatments behaved reasonably, but of those lacking financial incentives a larger proportion gave absurd responses. This suggests that data from decision experiments in which no financial incentives were should be treated as possibly contaminated and statistical methods robust against outliers employed.},
  file = {/Users/zhongyux/Zotero/storage/CS9FX6IX/Grether - 1992 - Testing bayes rule and the representativeness heur.pdf}
}

@article{holtUpdateBayesianUpdating2009,
  title = {An Update on {{Bayesian}} Updating},
  author = {Holt, Charles A. and Smith, Angela M.},
  year = {2009},
  month = feb,
  journal = {Journal of Economic Behavior \& Organization},
  series = {"{{Individual Decision-Making}}, {{Bayesian Estimation}} and {{Market Design}}: {{A Festschrift}} in Honor of {{David Grether}}"},
  volume = {69},
  number = {2},
  pages = {125--134},
  issn = {0167-2681},
  doi = {10.1016/j.jebo.2007.08.013},
  urldate = {2024-05-21},
  abstract = {This paper reports an experiment in which subjects are asked to assess probabilities for unknown events, with treatments that vary the extremity of the prior information. Probabilities are elicited using a Becker--DeGroot--Marshak procedure that does not depend on assumptions about risk aversion. The focus is on the pattern of biases in information processing.},
  keywords = {Baye's rule,Laboratory experiments,Probability weighting}
}

@article{barronBeliefUpdatingDoes2021,
  title = {Belief Updating: Does the `Good-News, Bad-News' Asymmetry Extend to Purely Financial Domains?},
  shorttitle = {Belief Updating},
  author = {Barron, Kai},
  year = {2021},
  month = mar,
  journal = {Experimental Economics},
  volume = {24},
  number = {1},
  pages = {31--58},
  issn = {1573-6938},
  doi = {10.1007/s10683-020-09653-z},
  urldate = {2024-05-21},
  abstract = {Bayes' statistical rule remains the status quo for modeling belief updating in both normative and descriptive models of behavior under uncertainty. Some recent research has questioned the use of Bayes' rule in descriptive models of behavior, presenting evidence that people overweight `good news' relative to `bad news' when updating ego-relevant beliefs. In this paper, we present experimental evidence testing whether this `good-news, bad-news' effect is present in a financial decision making context (i.e. a domain that is important for understanding much economic decision making). We find no evidence of asymmetric updating in this domain. In contrast, in our experiment, belief updating is close to the Bayesian benchmark on average. However, we show that this average behavior masks substantial heterogeneity in individual updating behavior. We find no evidence in support of a sizeable subgroup of asymmetric updators.},
  langid = {english},
  keywords = {Bayes' rule,Belief measurement,Belief updating,C11,C91,D83,Economic experiments,Motivated beliefs,Proper scoring rules},
  file = {/Users/zhongyux/Zotero/storage/GAXRZQA9/Barron - 2021 - Belief updating does the ‘good-news, bad-news’ as.pdf}
}

@misc{buserMeasuringResponsivenessFeedback2016,
  type = {{{SSRN Scholarly Paper}}},
  title = {Measuring {{Responsiveness}} to {{Feedback}} as a {{Personal Trait}}},
  author = {Buser, Thomas and Gerhards, Leonie and {van der Weele}, Joel J.},
  year = {2016},
  month = jun,
  number = {2789407},
  address = {Rochester, NY},
  doi = {10.2139/ssrn.2789407},
  urldate = {2024-05-21},
  abstract = {People typically update their beliefs about their own abilities too little in response to feed- back, a phenomenon known as ``conservatism'', and some studies suggest that they overweight good relative to bad signals (``asymmetry''). We measure individual conservatism and asymmetry in three tasks that test different cognitive skills, and study entry into a winner-takes-all competition based on similar skills. We show that individual differences in feedback responsiveness explain an important part of the variation in confidence and competition entry decisions. Conservatism is correlated across tasks and predicts competition entry both by influencing beliefs and independently of beliefs, suggesting it can be considered a personal trait. Subjects tend to be more conservative in tasks that they see as more ego-relevant and women are more conservative than men. Asymmetry is less stable across tasks, but predicts competition entry by increasing self-confidence.},
  langid = {english},
  keywords = {Bayesian updating,competitive behavior,confidence,feedback,identity},
  file = {/Users/zhongyux/Zotero/storage/F57PFUWQ/Buser et al. - 2016 - Measuring Responsiveness to Feedback as a Personal.pdf}
}

@article{couttsGoodNewsBad2019,
  title = {Good News and Bad News Are Still News: Experimental Evidence on Belief Updating},
  shorttitle = {Good News and Bad News Are Still News},
  author = {Coutts, Alexander},
  year = {2019},
  month = jun,
  journal = {Experimental Economics},
  volume = {22},
  number = {2},
  pages = {369--395},
  issn = {1573-6938},
  doi = {10.1007/s10683-018-9572-5},
  urldate = {2024-05-21},
  abstract = {Bayesian updating remains the benchmark for dynamic modeling under uncertainty within economics. Recent theory and evidence suggest individuals may process information asymmetrically when it relates to personal characteristics or future life outcomes, with good news receiving more weight than bad news. I examine information processing across a broad set of contexts: (1) ego relevant, (2) financially relevant, and (3) non value relevant. In the first two cases, information about outcomes is valenced, containing either good or bad news. In the third case, information is value neutral. In contrast to a number of previous studies I do not find differences in belief updating across valenced and value neutral settings. Updating across all contexts is asymmetric and conservative: the former is influenced by sequences of signals received, a new variation of confirmation bias, while the latter is driven by non-updates. Despite this, posteriors are well approximated by those calculated using Bayes' rule. Most importantly these patterns are present across all contexts, cautioning against the interpretation of asymmetric updating or other deviations from Bayes' rule as being motivated by psychological biases.},
  langid = {english},
  keywords = {Asymmetric belief updating,Bayes' rule,Beliefs,C91,Conservatism,D83,D84,Overconfidence},
  file = {/Users/zhongyux/Zotero/storage/PQ9872DL/Coutts - 2019 - Good news and bad news are still news experimenta.pdf}
}

@article{gotthard-realDesirabilityInformationProcessing2017,
  title = {Desirability and Information Processing: {{An}} Experimental Study},
  shorttitle = {Desirability and Information Processing},
  author = {{Gotthard-Real}, Alexander},
  year = {2017},
  month = mar,
  journal = {Economics Letters},
  volume = {152},
  pages = {96--99},
  issn = {0165-1765},
  doi = {10.1016/j.econlet.2017.01.012},
  urldate = {2024-05-21},
  abstract = {I study, in an experimental setting, how individuals process news regarding the likelihood of an event that is desirable, but not ego-relevant. I hypothesize that individuals biasedly favor good news over bad news, but find no support for this hypothesis.},
  keywords = {Bayes' rule,Belief updating,Optimism,Wishful thinking}
}

@article{mobiusManagingSelfConfidenceTheory2022,
  title = {Managing {{Self-Confidence}}: {{Theory}} and {{Experimental Evidence}}},
  shorttitle = {Managing {{Self-Confidence}}},
  author = {M{\"o}bius, Markus M. and Niederle, Muriel and Niehaus, Paul and Rosenblat, Tanya S.},
  year = {2022},
  month = nov,
  journal = {Management Science},
  volume = {68},
  number = {11},
  pages = {7793--7817},
  publisher = {INFORMS},
  issn = {0025-1909},
  doi = {10.1287/mnsc.2021.4294},
  urldate = {2024-05-21},
  abstract = {We use a series of experiments to understand whether and how people's beliefs about their own abilities are biased relative to the Bayesian benchmark and how these beliefs then affect behavior. We find that subjects systematically and substantially overweight positive feedback relative to negative (asymmetry) and also update too little overall (conservatism). These biases are substantially less pronounced in an ego-free control experiment. Updating does retain enough of the structure of Bayes' rule to let us model it coherently in an optimizing framework, in which, interestingly, asymmetry and conservatism emerge as complementary biases. We also find that exogenous changes in beliefs affect subjects' decisions to enter into a competition and do so similarly for more and less biased subjects, suggesting that people cannot ``undo'' their biases when the time comes to decide. This paper was accepted by Axel Ockenfels, behavioral economics and decision analysis. Funding: Financial support from the National Science Foundation (NSF), Harvard University, and Wesleyan University is gratefully acknowledged. P. Niehaus received financial support from an NSF Graduate Research Fellowship. Supplemental Material: The data files are available at https://doi.org/10.1287/mnsc.2021.4294.},
  keywords = {asymmetric belief updating,conservatism,information aversion,overconfidence},
  file = {/Users/zhongyux/Zotero/storage/AGBVWZNX/Möbius et al. - 2022 - Managing Self-Confidence Theory and Experimental .pdf}
}

@article{charnessConfirmationBiasMotivated2017,
  title = {Confirmation Bias with Motivated Beliefs},
  author = {Charness, Gary and Dave, Chetan},
  year = {2017},
  month = jul,
  journal = {Games and Economic Behavior},
  volume = {104},
  pages = {1--23},
  issn = {0899-8256},
  doi = {10.1016/j.geb.2017.02.015},
  urldate = {2024-05-21},
  abstract = {We investigate whether the confirmation bias is mitigated in signal-extraction environments by outside financial interests. We include a background strategic consideration leading to `motivated beliefs' for people in one role, as they receive higher equilibrium payoffs in a background game in one of two states, while people in the other role receive the same equilibrium payoffs in both. We find systematic differences in beliefs and our results suggest that players with motivated beliefs deviate less from Bayesian updating. However, such players still exhibit a confirmation bias in that they place additional weight on confirming information, in contrast to Bayesians.},
  keywords = {Bayesian updating,Confirmation bias,Experiment,Motivated beliefs}
}

@article{beachSampleProportionsSubjective1970,
  title = {Sample Proportions and Subjective Probability Revisions},
  author = {Beach, Lee Roy and Wise, James A. and Barclay, Scott},
  year = {1970},
  month = mar,
  journal = {Organizational Behavior and Human Performance},
  volume = {5},
  number = {2},
  pages = {183--190},
  issn = {0030-5073},
  doi = {10.1016/0030-5073(70)90014-0},
  urldate = {2024-05-21},
  abstract = {The hypothesis was that the proportions of poker chips in the displayed samples influence subjective probability revisions that are obtained in ``book bags-and-poker chips'' experiments. Subjects revised for simultaneous and sequential samples from two 80\%--20\% symmetrical binomial populations and two 70\%--30\% symmetrical binomial populations. Sample proportions account in large part for the revision responses for both kinds of populations for simultaneous samples. For sequential samples, however, proportions appeared to have less influence on revision responses even though 62\% of the subjects claimed to use them. The implications are discussed.}
}

@article{daveConfirmationBiasDeviations2003,
  title = {On {{Confirmation Bias}} and {{Deviations From Bayesian Updating}}},
  author = {Dave, Chetan and Wolfe, Katherine W},
  year = {2003},
  abstract = {Psychologists have documented several biases and heuristics that describe deviations from Bayesian updating in individual decision making under uncertainty. One particular notion, Confirmation Bias, predicts that individuals will exhibit systematic errors in updating despite the existence of learning opportunities. This paper formulates an experimental design to evaluate this behavioral heuristic within a non-strategic environment that motivates subjects financially. Subjects report probability estimates of the state of the world at the draw of each signal which may be conservative relative to a Bayesian. Indeed, pilot data indicate that both conservatism and confirmation bias are present in updating behavior.},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/L7NHNXUW/Dave and Wolfe - On Conﬁrmation Bias and Deviations From Bayesian U.pdf}
}

@misc{HowPeopleTake,
  title = {How {{Do People Take}} into {{Account Weight}}, {{Strength}} and {{Quality}} of {{Segregated}} vs. {{Aggregated Data}}? {{Experimental Evidence}} {\textbar} {{Journal}} of {{Risk}} and {{Uncertainty}}},
  urldate = {2024-05-21},
  howpublished = {https://link.springer.com/article/10.1023/B:RISK.0000038940.62992.1b},
  file = {/Users/zhongyux/Zotero/storage/PQXM9JER/BRISK.0000038940.62992.html}
}

@article{kraemerHowPeopleTake2004,
  title = {How {{Do People Take}} into {{Account Weight}}, {{Strength}} and {{Quality}} of {{Segregated}} vs. {{Aggregated Data}}? {{Experimental Evidence}}},
  shorttitle = {How {{Do People Take}} into {{Account Weight}}, {{Strength}} and {{Quality}} of {{Segregated}} vs. {{Aggregated Data}}?},
  author = {Kraemer, Carlo and Weber, Martin},
  year = {2004},
  month = sep,
  journal = {Journal of Risk and Uncertainty},
  volume = {29},
  number = {2},
  pages = {113--142},
  issn = {1573-0476},
  doi = {10.1023/B:RISK.0000038940.62992.1b},
  urldate = {2024-05-21},
  abstract = {In this experimental study we investigated how people aggregate two sets of signals about the state of the world to reach a single probability judgment. The signal sets may differ in the way signals are presented, in their number as well as their quality. By varying the presentation mode of the signals we investigated how people deal with segregated and aggregated evidence. We investigated whether subjects sufficiently take into account weight (number of signals), strength (composition) and quality of the information provided. The results indicate that consideration of the weight and strength of signals strongly depends on the type of their presentation. Particular patterns can be identified which determine if weight and/or strength are either under- or overweighted.},
  langid = {english},
  keywords = {Bayes' rule,heuristics,weight and strength of information},
  file = {/Users/zhongyux/Zotero/storage/7ZK7LPIH/Kraemer and Weber - 2004 - How Do People Take into Account Weight, Strength a.pdf}
}

@misc{sasakiBeliefUpdatingIndividual2007,
  type = {{{SSRN Scholarly Paper}}},
  title = {Belief {{Updating}} in {{Individual}} and {{Social Learning}}: {{A Field Experiment}} on the {{Internet}}},
  shorttitle = {Belief {{Updating}} in {{Individual}} and {{Social Learning}}},
  author = {Sasaki, Shunichiro and Kawagoe, Toshiji},
  year = {2007},
  month = may,
  number = {989689},
  address = {Rochester, NY},
  doi = {10.2139/ssrn.989689},
  urldate = {2024-05-21},
  abstract = {We conducted a field experiment on the Internet and investigated the participants' belief updating in an individual learning environment where they observe a sequence of private signals and in a social learning environment where they observe a sequence of other people's actions. We observed that participants do not update their posterior beliefs as efficiently as Bayesian, and that participants rely more on private signals than on other people's actions even when the informativeness of both is identical. Furthermore, we confirmed that participant's trust in other people's actions and their conformity to other people's actions are affected by their demographic characteristics.},
  langid = {english},
  keywords = {Belief updating,conformity,field experiment,individual learning,social learning},
  file = {/Users/zhongyux/Zotero/storage/HEIRYXGW/Sasaki and Kawagoe - 2007 - Belief Updating in Individual and Social Learning.pdf}
}

@article{mathysUncertaintyPerceptionHierarchical2014,
  title = {Uncertainty in Perception and the {{Hierarchical Gaussian Filter}}},
  author = {Mathys, Christoph D. and Lomakina, Ekaterina I. and Daunizeau, Jean and Iglesias, Sandra and Brodersen, Kay H. and Friston, Karl J. and Stephan, Klaas E.},
  year = {2014},
  month = nov,
  journal = {Frontiers in Human Neuroscience},
  volume = {8},
  publisher = {Frontiers},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2014.00825},
  urldate = {2024-05-29},
  abstract = {In its full sense, perception rests on an agent's model of how its sensory input comes about and the inferences it draws based on this model. These inferences are necessarily uncertain. Here, we illustrate how the hierarchical Gaussian filter (HGF) offers a principled and generic way to deal with the several forms that uncertainty in perception takes. The HGF is a recent derivation of one-step update equations from Bayesian principles that rests on a hierarchical generative model of the environment and its (in)stability. It is computationally highly efficient, allows for online estimates of hidden states, and has found numerous applications to experimental data from human subjects. In this paper, we generalize previous descriptions of the HGF and its account of perceptual uncertainty. First, we explicitly formulate the extension of the HGF's hierarchy to any number of levels; second, we discuss how various forms of uncertainty are accommodated by the minimization of variational free energy as encoded in the update equations; third, we combine the HGF with decision models and demonstrate the inversion of this combination; finally, we report a simulation study that compared four optimization methods for inverting the HGF/decision model combination at different noise levels. These four methods (Nelder-Mead simplex algorithm, Gaussian process-based global optimization, variational Bayes and Markov chain Monte Carlo sampling) all performed well even under considerable noise, with variational Bayes offering the best combination of efficiency and informativeness of inference. Our results demonstrate that the HGF provides a principled, flexible, and efficient - but at the same time intuitive - framework for the resolution of perceptual uncertainty in behaving agents.},
  langid = {english},
  keywords = {Bayesian inference,decision-making,filtering,free energy,hierarchical modeling,Learning,uncertainty,volatility},
  file = {/Users/zhongyux/Zotero/storage/BTMRB6JR/Mathys et al. - 2014 - Uncertainty in perception and the Hierarchical Gau.pdf}
}

@incollection{benjaminErrorsProbabilisticReasoning2019,
  title = {Errors in Probabilistic Reasoning and Judgment Biases},
  booktitle = {Handbook of {{Behavioral Economics}}: {{Applications}} and {{Foundations}} 1},
  author = {Benjamin, Daniel J.},
  year = {2019},
  volume = {2},
  pages = {69--186},
  publisher = {Elsevier},
  doi = {10.1016/bs.hesbe.2018.11.002},
  urldate = {2024-06-20},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  isbn = {978-0-444-63375-0},
  langid = {english},
  keywords = {Meta-Analysis},
  file = {/Users/zhongyux/Zotero/storage/CP2R4B9T/Benjamin - 2019 - Errors in probabilistic reasoning and judgment bia.pdf}
}

@article{fristonPredictionPerceptionAgency2012,
  title = {Prediction, Perception and Agency},
  author = {Friston, Karl},
  year = {2012},
  month = feb,
  journal = {International Journal of Psychophysiology},
  volume = {83},
  number = {2},
  pages = {248--252},
  issn = {01678760},
  doi = {10.1016/j.ijpsycho.2011.11.014},
  urldate = {2024-06-20},
  abstract = {The articles in this special issue provide a rich and thoughtful perspective on the brain as an inference machine. They illuminate key aspects of the internal or generative models the brain might use for perception. Furthermore, they explore the implications for a sense of agency and the nature of false inference in neuropsychiatric syndromes. In this review, I try to gather together some of the themes that emerge in this special issue and use them to illustrate how far one can take the notion of predictive coding in understanding behaviour and agency.},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/835RWK7N/Friston - 2012 - Prediction, perception and agency.pdf}
}

@misc{millidgePredictiveCodingTheoretical2022,
  title = {Predictive {{Coding}}: A {{Theoretical}} and {{Experimental Review}}},
  shorttitle = {Predictive {{Coding}}},
  author = {Millidge, Beren and Seth, Anil and Buckley, Christopher L.},
  year = {2022},
  month = jul,
  number = {arXiv:2107.12979},
  eprint = {2107.12979},
  primaryclass = {cs, q-bio},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2107.12979},
  urldate = {2024-06-20},
  abstract = {Predictive coding offers a potentially unifying account of cortical function -- postulating that the core function of the brain is to minimize prediction errors with respect to a generative model of the world. The theory is closely related to the Bayesian brain framework and, over the last two decades, has gained substantial influence in the fields of theoretical and cognitive neuroscience. A large body of research has arisen based on both empirically testing improved and extended theoretical and mathematical models of predictive coding, as well as in evaluating their potential biological plausibility for implementation in the brain and the concrete neurophysiological and psychological predictions made by the theory. Despite this enduring popularity, however, no comprehensive review of predictive coding theory, and especially of recent developments in this field, exists. Here, we provide a comprehensive review both of the core mathematical structure and logic of predictive coding, thus complementing recent tutorials in the literature. We also review a wide range of classic and recent work within the framework, ranging from the neurobiologically realistic microcircuits that could implement predictive coding, to the close relationship between predictive coding and the widely-used backpropagation of error algorithm, as well as surveying the close relationships between predictive coding and modern machine learning techniques.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Neural and Evolutionary Computing,Meta-Analysis,Quantitative Biology - Neurons and Cognition},
  file = {/Users/zhongyux/Zotero/storage/YHUZKJEM/Millidge et al. - 2022 - Predictive Coding a Theoretical and Experimental .pdf;/Users/zhongyux/Zotero/storage/QD7CQ42K/2107.html}
}

@article{mataAgingDecisionMaker2007,
  title = {The {{Aging Decision Maker}}: {{Cognitive Aging}} and the {{Adaptive Selection}} of {{Decision Strategies}}},
  author = {Mata, Rui and Schooler, Lael J and Rieskamp, Jorg},
  year = {2007},
  abstract = {Are older adults' decision abilities fundamentally compromised by age-related cognitive decline? Or can they adaptively select decision strategies? One study (N ϭ 163) investigated the impact of cognitive aging on the ability to select decision strategies as a function of environment structure. Participants made decisions in either an environment that favored the use of information-intensive strategies or one favoring the use of simple, information-frugal strategies. Older adults tended to (a) look up less information and take longer to process it and (b) use simpler, less cognitively demanding strategies. In accordance with the idea that age-related cognitive decline leads to reliance on simpler strategies, measures of fluid intelligence explained age-related differences in information search and strategy selection. Nevertheless, both young and older adults seem to be equally adapted decision makers in that they adjust their information search and strategy selection as a function of environment structure, suggesting that the aging decision maker is an adaptive one.},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/CPPPIV2X/Mata et al. - The Aging Decision Maker Cognitive Aging and the .pdf}
}

@book{jeffreysTheoryProbability1998,
  title = {The {{Theory}} of {{Probability}}},
  author = {Jeffreys, Harold},
  year = {1998},
  month = aug,
  publisher = {OUP Oxford},
  abstract = {Another title in the reissued Oxford Classic Texts in the Physical Sciences series, Jeffrey's Theory of Probability, first published in 1939, was the first to develop a fundamental theory of scientific inference based on the ideas of Bayesian statistics. His ideas were way ahead of their time and it is only in the past ten years that the subject of Bayes' factors has been significantly developed and extended. Until recently the two schools of statistics (Bayesian and Frequentist) were distinctly different and set apart. Recent work (aided by increased computer power and availability) has changed all that and today's graduate students and researchers all require an understanding of Bayesian ideas. This book is their starting point.},
  googlebooks = {vh9Act9rtzQC},
  isbn = {978-0-19-158967-6},
  langid = {english},
  keywords = {Mathematics / Applied,Mathematics / Discrete Mathematics,Mathematics / Probability & Statistics / General,Science / Physics / General}
}

@article{francoGenericPropertiesComputational2021,
  title = {Generic Properties of a Computational Task Predict Human Effort and Performance},
  author = {Franco, Juan Pablo and Yadav, Nitin and Bossaerts, Peter and Murawski, Carsten},
  year = {2021},
  month = sep,
  journal = {Journal of Mathematical Psychology},
  volume = {104},
  pages = {102592},
  issn = {00222496},
  doi = {10.1016/j.jmp.2021.102592},
  urldate = {2024-06-24},
  abstract = {It has been shown that computational hardness of cognitive tasks affects people's effort and ability to solve problems reliably. However, prior empirical studies lack generality. They quantify computational hardness of tasks based on particular algorithms or for specific problems. Here, we propose a set of measures of computational hardness of individual instances of a task in a way that is independent of any algorithm or computational model and can be generalized to other problems. Specifically, we introduce two measures, typical-case complexity (TCC), a measure of average hardness of a random ensemble of instances, and instance complexity (IC), an instance-specific metric. Both measures are related to structural properties of instances. We then test the effect of those measures on human behavior by asking participants to solve instances of two variants of the 0-1 knapsack problem, a canonical and ubiquitous NP-hard problem. We find that participants spent more time on instances with higher TCC and IC, but that decision quality was lower in those instances. We propose that the study of mathematical properties of tasks related to computational hardness can contribute to the development of computationally plausible accounts of human decision-making, just like stochastic properties have proven to be critical to our understanding of human decisions in probabilistic tasks.},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/CQXD4H4K/Franco et al. - 2021 - Generic properties of a computational task predict.pdf}
}

@article{achtzigerFastRationalResponseTimes2014,
  title = {Fast or {{Rational}}? {{A Response-Times Study}} of {{Bayesian Updating}}},
  shorttitle = {Fast or {{Rational}}?},
  author = {Achtziger, Anja and {Al{\'o}s-Ferrer}, Carlos},
  year = {2014},
  month = apr,
  journal = {Management Science},
  doi = {10.1287/mnsc.2013.1793},
  abstract = {We present a simple model for decision making under uncertainty building on dual-process theories from psychology, and use it to illustrate a possible component of intuitive decision making of particular relevance for managerial settings. Decisions are the result of the interaction between two decision processes. The first one captures optimization based on Bayesian updating of beliefs. The second corresponds to a form of reinforcement learning capturing the tendency to rely on past performance. The model predicts that (i) in case of conflict between the two processes, correct responses are associated with longer response times, but (ii) if both processes are aligned, errors are slower. Further, (iii) response times in case of conflict are longer than in case of alignment. We confirm the predictions of the model in an experiment using a paradigm where an associative win-stay, lose-shift process conflicted with rational belief updating.}
}

@article{alos-ferrerFaithIntuitionBehavioral2012,
  title = {Faith in Intuition and Behavioral Biases},
  author = {{Al{\'o}s-Ferrer}, Carlos and H{\"u}gelsch{\"a}fer, Sabine},
  year = {2012},
  month = sep,
  journal = {Journal of Economic Behavior \& Organization},
  volume = {84},
  number = {1},
  pages = {182--192},
  issn = {0167-2681},
  doi = {10.1016/j.jebo.2012.08.004},
  urldate = {2024-07-31},
  abstract = {We use a 15-item self-report questionnaire known as ``Faith in Intuition'' to measure reliance on intuitive decision making, and ask whether the latter correlates with behavioral biases involving a failure of Bayesian updating. In a first experiment, we find that higher report scores are associated with an increased use of the representativeness heuristic (overweighting sample information). We find no evidence of increased conservatism (overweighting prior information). The results of a second experiment show that more intuitive decision makers rely more often on the ``reinforcement heuristic'' where successful decisions are repeated even if correctly updating prior beliefs indicates otherwise. However, this effect depends on the magnitude of incentives.},
  keywords = {Bayesian updating,Behavioral biases,Conservatism,Intuition,Reinforcement,Representativeness},
  file = {/Users/zhongyux/Zotero/storage/Z3IS2JGY/S0167268112001564.html}
}

@article{cooperComputationalComplexityProbabilistic1990,
  title = {The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks},
  author = {Cooper, Gregory F.},
  year = {1990},
  month = mar,
  journal = {Artificial Intelligence},
  volume = {42},
  number = {2},
  pages = {393--405},
  issn = {0004-3702},
  doi = {10.1016/0004-3702(90)90060-D},
  urldate = {2024-08-03},
  abstract = {Bayesian belief networks provide a natural, efficient method for representing probabilistic dependencies among a set of variables. For these reasons, numerous researchers are exploring the use of belief networks as a knowledge representation in artificial intelligence. Algorithms have been developed previously for efficient probabilistic inference using special classes of belief networks. More general classes of belief networks, however, have eluded efforts to develop efficient inference algorithms. We show that probabilistic inference using belief networks is NP-hard. Therefore, it seems unlikely that an exact algorithm can be developed to perform probabilistic inference efficiently over all classes of belief networks. This result suggests that research should be directed away from the search for a general, efficient probabilistic inference algorithm, and toward the design of efficient special-case, average-case, and approximation algorithms.},
  file = {/Users/zhongyux/Zotero/storage/I5C2YZ8K/000437029090060D.html}
}

@article{lipkusGeneralPerformanceNumeracy2001,
  title = {General {{Performance}} on a {{Numeracy Scale}} among {{Highly Educated Samples}}},
  author = {Lipkus, Isaac M. and Samsa, Greg and Rimer, Barbara K.},
  year = {2001},
  month = feb,
  journal = {Medical Decision Making},
  volume = {21},
  number = {1},
  pages = {37--44},
  publisher = {SAGE Publications Inc STM},
  issn = {0272-989X},
  doi = {10.1177/0272989X0102100105},
  urldate = {2024-08-05},
  abstract = {Background. Numeracy, how facile people are with basic probability and mathematical concepts, is associated with how people perceive health risks. Performance on simple numeracy problems has been poor among populations with little as well as more formal education. Here, we examine how highly educated participants performed on a general and an expanded numeracy scale. The latter was designed within the context of health risks. Method. A total of 463 men and women aged 40 and older completed a 3-item general and an expanded 7-item numeracy scale. The expanded scale assessed how well people 1) differentiate and perform simple mathematical operations on risk magnitudes using percentages and proportions, 2) convert percentages to proportions, 3) convert proportions to percentages, and 4) convert probabilities to proportions. Results. On average, 18\% and 32\% of participants correctly answered all of the general and expanded numeracy scale items. Approximately 16\% to 20\% incorrectly answered the most straightforward questions pertaining to risk magnitudes (e.g., Which represents the larger risk: 1\%, 5\%, or 10\%?). A factor analysis revealed that the general and expanded risk numeracy items tapped the construct of global numeracy. Conclusions. These results suggest that even highly educated participants have difficulty with relatively simple numeracy questions, thus replicating in part earlier studies. The implication is that usual strategies for communicating numerical risk may be flawed. Methods and consequences of communicating health risk information tailored to a person's level of numeracy should be explored further.},
  langid = {english},
  file = {/Users/zhongyux/Zotero/storage/BUP3W3LS/Lipkus et al. - 2001 - General Performance on a Numeracy Scale among High.pdf}
}
